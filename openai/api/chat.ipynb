{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-26T15:02:16.217868Z",
     "start_time": "2024-01-26T15:02:16.209773Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化环境\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = 'https://key.wenwen-ai.com/v1'\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-6V2exWFBSa2lmuZ7C0D773D1BaEd4fB7A1B6A0A265D550C6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89bab9e7181fa24e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T15:02:21.042381Z",
     "start_time": "2024-01-26T15:02:18.432944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"chatcmpl-8lI0hdhhCWbcrhJ2z3OLxbq4hb56u\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"message\": {\"content\": \"Hello! How can I assist you today?\", \"role\": \"assistant\", \"function_call\": null, \"tool_calls\": null}, \"logprobs\": null}], \"created\": 1706281339, \"model\": \"gpt-4-0125-preview\", \"object\": \"chat.completion\", \"system_fingerprint\": \"fp_376b7f78b9\", \"usage\": {\"completion_tokens\": 9, \"prompt_tokens\": 20, \"total_tokens\": 29}}\n"
     ]
    }
   ],
   "source": [
    "# 一般参数\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello! \"}\n",
    "    ],\n",
    "    n=1,\n",
    "    max_tokens=2048,\n",
    "    temperature=0.8,\n",
    "    # top_p=1,\n",
    "    # stop=\"!\",\n",
    "    # seed=1234567,\n",
    "    # user=\"user_1234567\",\n",
    ")\n",
    "\n",
    "print(completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"chatcmpl-8jQRQLehUtzusg7vkdONa6hnUuZEv\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"message\": {\"content\": \"\\u4f60\\u597d\\uff0c\\u6211\\u7684\\u540d\\u5b57\\u662f\\u5c0f\\u95ee\\u3002\\u8981\\u5165\\u95e8\\u5b66\\u4e60Python\\uff0c\\u4f60\\u53ef\\u4ee5\\u6309\\u7167\\u4ee5\\u4e0b\\u6b65\\u9aa4\\u8fdb\\u884c\\uff1a\\n\\n1. \\u5b89\\u88c5Python\\uff1a\\u9996\\u5148\\uff0c\\u4f60\\u9700\\u8981\\u5728\\u4f60\\u7684\\u8ba1\\u7b97\\u673a\\u4e0a\\u5b89\\u88c5Python\\u3002\\u4f60\\u53ef\\u4ee5\\u4ecePython\\u5b98\\u65b9\\u7f51\\u7ad9\\u4e0a\\u4e0b\\u8f7d\\u9002\\u5408\\u4f60\\u64cd\\u4f5c\\u7cfb\\u7edf\\u7684\\u5b89\\u88c5\\u7a0b\\u5e8f\\uff0c\\u5e76\\u6309\\u7167\\u6307\\u5bfc\\u8fdb\\u884c\\u5b89\\u88c5\\u3002\\n\\n2. \\u5b66\\u4e60\\u57fa\\u7840\\u77e5\\u8bc6\\uff1a\\u4e00\\u65e6\\u5b89\\u88c5\\u5b8c\\u6210\\uff0c\\u4f60\\u53ef\\u4ee5\\u5f00\\u59cb\\u5b66\\u4e60Python\\u7684\\u57fa\\u7840\\u77e5\\u8bc6\\uff0c\\u6bd4\\u5982\\u53d8\\u91cf\\u3001\\u6570\\u636e\\u7c7b\\u578b\\u3001\\u6761\\u4ef6\\u8bed\\u53e5\\u3001\\u5faa\\u73af\\u7b49\\u3002\\u4f60\\u53ef\\u4ee5\\u901a\\u8fc7\\u9605\\u8bfbPython\\u7684\\u5b98\\u65b9\\u6587\\u6863\\u6216\\u8005\\u53c2\\u8003\\u4e00\\u4e9b\\u5165\\u95e8\\u6559\\u7a0b\\u6765\\u5b66\\u4e60\\u8fd9\\u4e9b\\u5185\\u5bb9\\u3002\\n\\n3. \\u7f16\\u5199\\u4ee3\\u7801\\uff1a\\u5b66\\u4e60\\u7406\\u8bba\\u77e5\\u8bc6\\u7684\\u540c\\u65f6\\uff0c\\u4f60\\u4e5f\\u5e94\\u8be5\\u5c1d\\u8bd5\\u7f16\\u5199\\u4e00\\u4e9b\\u7b80\\u5355\\u7684Python\\u7a0b\\u5e8f\\u6765\\u5de9\\u56fa\\u6240\\u5b66\\u5185\\u5bb9\\u3002\\u53ef\\u4ee5\\u4ece\\u8f93\\u51fa\\\"Hello, World!\\\"\\u5f00\\u59cb\\uff0c\\u7136\\u540e\\u9010\\u6e10\\u6269\\u5927\\u4f60\\u7684\\u7f16\\u7a0b\\u8303\\u56f4\\u3002\\n\\n4. \\u5b66\\u4e60\\u6570\\u636e\\u7ed3\\u6784\\u548c\\u7b97\\u6cd5\\uff1a\\u4e00\\u65e6\\u4f60\\u638c\\u63e1\\u4e86Python\\u7684\\u57fa\\u7840\\u77e5\\u8bc6\\uff0c\\u4f60\\u53ef\\u4ee5\\u5f00\\u59cb\\u5b66\\u4e60\\u4e00\\u4e9b\\u66f4\\u9ad8\\u7ea7\\u7684\\u4e3b\\u9898\\uff0c\\u6bd4\\u5982\\u6570\\u636e\\u7ed3\\u6784\\u548c\\u7b97\\u6cd5\\uff0c\\u8fd9\\u5bf9\\u4e8e\\u7f16\\u5199\\u66f4\\u590d\\u6742\\u7684\\u7a0b\\u5e8f\\u975e\\u5e38\\u91cd\\u8981\\u3002\\n\\n5. \\u5b9e\\u8df5\\u9879\\u76ee\\uff1a\\u6700\\u540e\\uff0c\\u4f60\\u53ef\\u4ee5\\u5c1d\\u8bd5\\u53c2\\u4e0e\\u4e00\\u4e9b\\u5c0f\\u578b\\u9879\\u76ee\\u6216\\u8005\\u7ec3\\u4e60\\uff0c\\u901a\\u8fc7\\u5b9e\\u8df5\\u6765\\u52a0\\u6df1\\u5bf9Python\\u7684\\u7406\\u89e3\\u548c\\u638c\\u63e1\\u3002\\n\\n\\u5e0c\\u671b\\u8fd9\\u4e9b\\u6b65\\u9aa4\\u80fd\\u591f\\u5e2e\\u52a9\\u4f60\\u5165\\u95e8\\u5b66\\u4e60Python\\u3002\\u5982\\u679c\\u4f60\\u6709\\u4efb\\u4f55\\u95ee\\u9898\\uff0c\\u90fd\\u53ef\\u4ee5\\u968f\\u65f6\\u5411\\u6211\\u63d0\\u95ee\\u3002\", \"role\": \"assistant\", \"function_call\": null, \"tool_calls\": null}, \"logprobs\": null}], \"created\": 1705837092, \"model\": \"gpt-3.5-turbo-1106\", \"object\": \"chat.completion\", \"system_fingerprint\": \"fp_aaa20cc2ba\", \"usage\": {\"completion_tokens\": 402, \"prompt_tokens\": 43, \"total_tokens\": 445}}\n"
     ]
    }
   ],
   "source": [
    "# system message 一般用作一个整体的\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个python专家，你的名字叫小问\"},\n",
    "        # {\"role\": \"user\", \"content\": \"你是一个python专家，你的名字叫小问\"},\n",
    "        {\"role\": \"user\", \"content\": \"你的名字是什么？如何入门学习python\"}\n",
    "    ],\n",
    "    n=1,\n",
    "    max_tokens=2048,\n",
    "    temperature=0.8,\n",
    ")\n",
    "\n",
    "print(completion.model_dump_json())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:38:21.892573Z",
     "start_time": "2024-01-21T11:38:11.488575Z"
    }
   },
   "id": "642cdabf012d2056"
  },
  {
   "cell_type": "markdown",
   "id": "29d149aa3946273f",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'. (request id: 20240121122959735066473AEkDkcoT)\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mopenai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m completion_create_params\n\u001B[1;32m      5\u001B[0m client \u001B[38;5;241m=\u001B[39m OpenAI()\n\u001B[0;32m----> 7\u001B[0m completion \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m      8\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo-1106\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      9\u001B[0m     messages\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m     10\u001B[0m         {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are a helpful assistant\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m     11\u001B[0m         {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWho won the world series in 2020?\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m     12\u001B[0m     ],\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;66;03m# 对content进行json格式化\u001B[39;00m\n\u001B[1;32m     14\u001B[0m     response_format\u001B[38;5;241m=\u001B[39mcompletion_create_params\u001B[38;5;241m.\u001B[39mResponseFormat(\u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson_object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m )\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(completion\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mmodel_dump_json())\n",
      "File \u001B[0;32m~/anaconda3/envs/openai_api_python/lib/python3.11/site-packages/openai/_utils/_utils.py:301\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    299\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 301\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/openai_api_python/lib/python3.11/site-packages/openai/resources/chat/completions.py:598\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    552\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    553\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    596\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    597\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[0;32m--> 598\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[1;32m    599\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/chat/completions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    600\u001B[0m         body\u001B[38;5;241m=\u001B[39mmaybe_transform(\n\u001B[1;32m    601\u001B[0m             {\n\u001B[1;32m    602\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: messages,\n\u001B[1;32m    603\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: model,\n\u001B[1;32m    604\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrequency_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: frequency_penalty,\n\u001B[1;32m    605\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction_call\u001B[39m\u001B[38;5;124m\"\u001B[39m: function_call,\n\u001B[1;32m    606\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunctions\u001B[39m\u001B[38;5;124m\"\u001B[39m: functions,\n\u001B[1;32m    607\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogit_bias\u001B[39m\u001B[38;5;124m\"\u001B[39m: logit_bias,\n\u001B[1;32m    608\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: max_tokens,\n\u001B[1;32m    609\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m\"\u001B[39m: n,\n\u001B[1;32m    610\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpresence_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: presence_penalty,\n\u001B[1;32m    611\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_format\u001B[39m\u001B[38;5;124m\"\u001B[39m: response_format,\n\u001B[1;32m    612\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m: seed,\n\u001B[1;32m    613\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop\u001B[39m\u001B[38;5;124m\"\u001B[39m: stop,\n\u001B[1;32m    614\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream,\n\u001B[1;32m    615\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m: temperature,\n\u001B[1;32m    616\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtool_choice\u001B[39m\u001B[38;5;124m\"\u001B[39m: tool_choice,\n\u001B[1;32m    617\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtools\u001B[39m\u001B[38;5;124m\"\u001B[39m: tools,\n\u001B[1;32m    618\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_p\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_p,\n\u001B[1;32m    619\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m: user,\n\u001B[1;32m    620\u001B[0m             },\n\u001B[1;32m    621\u001B[0m             completion_create_params\u001B[38;5;241m.\u001B[39mCompletionCreateParams,\n\u001B[1;32m    622\u001B[0m         ),\n\u001B[1;32m    623\u001B[0m         options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[1;32m    624\u001B[0m             extra_headers\u001B[38;5;241m=\u001B[39mextra_headers, extra_query\u001B[38;5;241m=\u001B[39mextra_query, extra_body\u001B[38;5;241m=\u001B[39mextra_body, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[1;32m    625\u001B[0m         ),\n\u001B[1;32m    626\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mChatCompletion,\n\u001B[1;32m    627\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    628\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mStream[ChatCompletionChunk],\n\u001B[1;32m    629\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/openai_api_python/lib/python3.11/site-packages/openai/_base_client.py:1063\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1049\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1050\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1051\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1058\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1059\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1060\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1061\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1062\u001B[0m     )\n\u001B[0;32m-> 1063\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[0;32m~/anaconda3/envs/openai_api_python/lib/python3.11/site-packages/openai/_base_client.py:842\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    833\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    834\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    835\u001B[0m     cast_to: Type[ResponseT],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    840\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    841\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m--> 842\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m    843\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m    844\u001B[0m         options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m    845\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m    846\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m    847\u001B[0m         remaining_retries\u001B[38;5;241m=\u001B[39mremaining_retries,\n\u001B[1;32m    848\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/openai_api_python/lib/python3.11/site-packages/openai/_base_client.py:885\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    882\u001B[0m     \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m    883\u001B[0m     \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m    884\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m--> 885\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    886\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mTimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    887\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[0;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'. (request id: 20240121122959735066473AEkDkcoT)\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}"
     ]
    }
   ],
   "source": [
    "# response_format 参数 https://platform.openai.com/docs/guides/text-generation/json-mode\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import completion_create_params\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n",
    "    ],\n",
    "    # 对content进行json格式化\n",
    "    response_format=completion_create_params.ResponseFormat(type=\"json_object\")\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.model_dump_json())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T12:30:00.158549Z",
     "start_time": "2024-01-21T12:29:58.955996Z"
    }
   },
   "id": "9387f85fb440a34c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516bdf352343e73f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T13:14:48.519855Z",
     "start_time": "2023-12-27T13:14:48.462304Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"content\":\"\",\"function_call\":null,\"role\":\"assistant\",\"tool_calls\":null}\n",
      "{\"content\":\"Hello\",\"function_call\":null,\"role\":null,\"tool_calls\":null}\n",
      "{\"content\":\"!\",\"function_call\":null,\"role\":null,\"tool_calls\":null}\n",
      "{\"content\":\" How\",\"function_call\":null,\"role\":null,\"tool_calls\":null}\n",
      "{\"content\":\" can\",\"function_call\":null,\"role\":null,\"tool_calls\":null}\n",
      "{\"content\":\" I\",\"function_call\":null,\"role\":null,\"tool_calls\":null}\n",
      "{\"content\":\" assist\",\"function_call\":null,\"role\":null,\"tool_calls\":null}\n",
      "{\"content\":\" you\",\"function_call\":null,\"role\":null,\"tool_calls\":null}\n",
      "{\"content\":\" today\",\"function_call\":null,\"role\":null,\"tool_calls\":null}\n",
      "{\"content\":\"?\",\"function_call\":null,\"role\":null,\"tool_calls\":null}\n",
      "{\"content\":null,\"function_call\":null,\"role\":null,\"tool_calls\":null}\n"
     ]
    }
   ],
   "source": [
    "# stream流式输出\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.model_dump_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9906]\n",
      "{\"content\":\"Hi there! How can I assist you today?\",\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":null}\n"
     ]
    }
   ],
   "source": [
    "# logit_bias参数\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "print(enc.encode(\"Hello\"))\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ],\n",
    "    logit_bias={enc.encode(\"Hello\")[0]: -100}\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.model_dump_json())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:09:41.212810Z",
     "start_time": "2023-12-28T15:09:38.541734Z"
    }
   },
   "id": "ed7fc0f026699c4f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eada43c111acf25",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T13:26:37.059608Z",
     "start_time": "2023-12-27T13:26:34.817456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"content\":\"Hello! How can I assist you today?\",\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":null}\n",
      "{\"content\":[{\"token\":\"Hello\",\"bytes\":[72,101,108,108,111],\"logprob\":-0.21570958,\"top_logprobs\":[{\"token\":\"Hello\",\"bytes\":[72,101,108,108,111],\"logprob\":-0.21570958},{\"token\":\"Hi\",\"bytes\":[72,105],\"logprob\":-1.6720008}]},{\"token\":\"!\",\"bytes\":[33],\"logprob\":-0.20926832,\"top_logprobs\":[{\"token\":\"!\",\"bytes\":[33],\"logprob\":-0.20926832},{\"token\":\" there\",\"bytes\":[32,116,104,101,114,101],\"logprob\":-1.6910303}]},{\"token\":\" How\",\"bytes\":[32,72,111,119],\"logprob\":-0.00095136015,\"top_logprobs\":[{\"token\":\" How\",\"bytes\":[32,72,111,119],\"logprob\":-0.00095136015},{\"token\":\" Is\",\"bytes\":[32,73,115],\"logprob\":-7.526584}]},{\"token\":\" can\",\"bytes\":[32,99,97,110],\"logprob\":-0.014271167,\"top_logprobs\":[{\"token\":\" can\",\"bytes\":[32,99,97,110],\"logprob\":-0.014271167},{\"token\":\" are\",\"bytes\":[32,97,114,101],\"logprob\":-4.673554}]},{\"token\":\" I\",\"bytes\":[32,73],\"logprob\":-0.00001700133,\"top_logprobs\":[{\"token\":\" I\",\"bytes\":[32,73],\"logprob\":-0.00001700133},{\"token\":\" i\",\"bytes\":[32,105],\"logprob\":-11.576181}]},{\"token\":\" assist\",\"bytes\":[32,97,115,115,105,115,116],\"logprob\":-0.32928452,\"top_logprobs\":[{\"token\":\" assist\",\"bytes\":[32,97,115,115,105,115,116],\"logprob\":-0.32928452},{\"token\":\" help\",\"bytes\":[32,104,101,108,112],\"logprob\":-1.2748374}]},{\"token\":\" you\",\"bytes\":[32,121,111,117],\"logprob\":-0.000036789137,\"top_logprobs\":[{\"token\":\" you\",\"bytes\":[32,121,111,117],\"logprob\":-0.000036789137},{\"token\":\" or\",\"bytes\":[32,111,114],\"logprob\":-10.491168}]},{\"token\":\" today\",\"bytes\":[32,116,111,100,97,121],\"logprob\":-0.0055119265,\"top_logprobs\":[{\"token\":\" today\",\"bytes\":[32,116,111,100,97,121],\"logprob\":-0.0055119265},{\"token\":\"?\",\"bytes\":[63],\"logprob\":-5.204969}]},{\"token\":\"?\",\"bytes\":[63],\"logprob\":-0.00003333223,\"top_logprobs\":[{\"token\":\"?\",\"bytes\":[63],\"logprob\":-0.00003333223},{\"token\":\"?\\n\",\"bytes\":[63,10],\"logprob\":-10.532458}]}]}\n"
     ]
    }
   ],
   "source": [
    "# logprobs参数\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ],\n",
    "    logprobs=True,\n",
    "    top_logprobs=2\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.model_dump_json())\n",
    "print(completion.choices[0].logprobs.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "688798678be4ae7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:50:24.530133Z",
     "start_time": "2023-12-26T14:50:22.130277Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-8a338gVY0y65AzAMrajrFvVHrXPVV\",\"choices\":[{\"finish_reason\":\"tool_calls\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":null,\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":[{\"id\":\"call_yAjy5Ktcqn1unsqt9XgPRWku\",\"function\":{\"arguments\":\"{\\\"location\\\":\\\"Boston, MA\\\",\\\"unit\\\":\\\"celsius\\\"}\",\"name\":\"get_current_weather\"},\"type\":\"function\"}]}}],\"created\":1703602222,\"model\":\"gpt-3.5-turbo-1106\",\"object\":\"chat.completion\",\"system_fingerprint\":\"fp_772e8125bb\",\"usage\":{\"completion_tokens\":22,\"prompt_tokens\":83,\"total_tokens\":105}}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "print(completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d427b98061dc80a7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T12:34:23.308404Z",
     "start_time": "2024-01-21T12:34:16.049331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"finish_reason\": \"stop\", \"index\": 0, \"message\": {\"content\": \"This is a scenic image of a wooden boardwalk or pathway extending through a lush, green meadow or wetland area. The long grasses on either side of the boardwalk hint at a natural, possibly protected environment. The sky is partly cloudy with ample blue areas, suggesting it might be a pleasant day. Trees and shrubs are visible in the distance, possibly marking the end of this area or a transition to a different ecosystem. The scene is tranquil and invites walking or nature observation.\", \"role\": \"assistant\", \"function_call\": null, \"tool_calls\": null}}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0].model_dump_json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
